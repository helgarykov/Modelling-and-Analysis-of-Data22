{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Define the number of neighbors to consider\n",
    "n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the number of neighbors\n",
    "for k in n_neighbors:\n",
    "    # Create a KNeighborsClassifier object with the number of neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Fit the model to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    # Compute the RMSE and prediction accuracy\n",
    "    rmse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # Append the results to the list\n",
    "    results.append((k, rmse, accuracy))\n",
    "\n",
    "# Print the results\n",
    "for k, rmse, accuracy in results:\n",
    "    print(\"k = %d: RMSE = %f, Accuracy = %f\" % (k, rmse, accuracy))\n",
    "\n",
    "#In this example, X_train and y_train are the training data and labels, \n",
    "# and X_test and y_test are the test data and labels. The KNeighborsClassifier \n",
    "# object is created with the number of neighbors specified by the variable k. \n",
    "# The model is fit to the training data, and predictions are made on the test set. \n",
    "# The root mean squared error (RMSE) and prediction accuracy are computed and stored \n",
    "# in the results list. Finally, the results are printed for each value of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NearestNeighborsClassifier:\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = np.zeros(X_test.shape[0])\n",
    "        for i, x_test in enumerate(X_test):\n",
    "            distances = np.sum((self.X - x_test) ** 2, axis=1)\n",
    "            nearest_neighbors = np.argsort(distances)[:self.n_neighbors]\n",
    "            y_pred[i] = np.argmax(np.bincount(self.y[nearest_neighbors]))\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NearestNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "rmse = np.sqrt(mean_squared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def knn_classify(train_data, train_labels, test_data, k):\n",
    "    \"\"\"\n",
    "    Classifies test data using k-nearest neighbors method.\n",
    "    \n",
    "    Parameters:\n",
    "    train_data: numpy array of shape (n_samples, n_features)\n",
    "        The training data.\n",
    "    train_labels: numpy array of shape (n_samples,)\n",
    "        The labels for the training data.\n",
    "    test_data: numpy array of shape (n_samples, n_features)\n",
    "        The test data.\n",
    "    k: int\n",
    "        Number of nearest neighbors to consider.\n",
    "        \n",
    "    Returns:\n",
    "    predictions: numpy array of shape (n_samples,)\n",
    "        The predicted labels for the test data.\n",
    "    \"\"\"\n",
    "    # Calculate the distances between the test data and the training data\n",
    "    distances = np.sqrt(np.sum((train_data - test_data[:, np.newaxis])**2, axis=2))\n",
    "    \n",
    "    # Find the indices of the k closest training samples for each test sample\n",
    "    k_nearest = np.argpartition(distances, k, axis=1)[:, :k]\n",
    "    \n",
    "    # Get the labels of the k closest training samples for each test sample\n",
    "    k_nearest_labels = train_labels[k_nearest]\n",
    "    \n",
    "    # Find the most common label among the k nearest neighbors\n",
    "    predictions = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=k_nearest_labels)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your train data and train labels\n",
    "train_data = ...\n",
    "train_labels =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        self.X = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], ... ] # predefined matrix X with shape (500, 4)\n",
    "        self.t = [1, 2, 3, 4, 5, ... ] # target values with shape (500,)\n",
    "        self.k = 5 # number of nearest neighbors to consider\n",
    "\n",
    "    def __numericalDistance(self, p, q):\n",
    "        distance = math.sqrt(sum((p[i] - q[i]) ** 2 for i in range(len(p))))\n",
    "        return distance\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        distances = []\n",
    "        for i in range(len(self.X)):\n",
    "            distances.append((i, self.__numericalDistance(self.X[i], new_data)))\n",
    "        # sort the distances in ascending order\n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        # take the k nearest neighbors\n",
    "        nearest_neighbors = distances[:self.k]\n",
    "        # calculate the prediction\n",
    "        prediction = round(1/self.k * sum(self.t[x[0]] for x in nearest_neighbors))\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        self.X = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], ... ] # predefined matrix X with shape (500, 4)\n",
    "        self.t = [1, 2, 3, 4, 5, ... ] # target values with shape (500,)\n",
    "        self.k_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        self.neighbors_indices = []\n",
    "    # ... other methods\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        predictions = []\n",
    "        for k in self.k_values:\n",
    "            distances = []\n",
    "            for i in range(len(self.X)):\n",
    "                distances.append((i, self.__numericalDistance(self.X[i], new_data)))\n",
    "            distances.sort(key=lambda x: x[1])\n",
    "            nearest_neighbors = distances[:k]\n",
    "            self.neighbors_indices.append([x[0] for x in nearest_neighbors])\n",
    "            predictions.append(np.round(1/k * np.sum(self.t[x[0]] for x in nearest_neighbors)))\n",
    "        return predictions\n",
    "    def get_target_values(self):\n",
    "        target_values = []\n",
    "        for i in range(len(self.k_values)):\n",
    "            target_values.append([self.t[x] for x in self.neighbors_indices[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the train data into train set and validation set\n",
    "# Shuffle the data\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "# Calculate the size of the validation set\n",
    "val_size = int(train_data.shape[0] * 0.2)\n",
    "\n",
    "# Create the validation set by taking the first `val_size` elements of the shuffled data\n",
    "val_data = train_data[:val_size]\n",
    "\n",
    "# Create the training set by taking the remaining elements of the shuffled data\n",
    "train_data = train_data[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(t)\n",
    "        error = (t-tp)**2\n",
    "        rmse = math.sqrt(np.sum(error)/n)\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #def predict(self, X):\n",
    "        \"\"\"\n",
    "        Computes predictions on the test set for a new set of points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : Array of length n_samples\n",
    "        \"\"\"  \n",
    "        # returns 10 predictions for 10 nearest neighbours\n",
    "        #predictions = []\n",
    "        #for n_neighbours in self.n_neighbors:\n",
    "            #distances = []\n",
    "            #for i in range(len(self.X)):\n",
    "                #distances.append((i, self.__mixedDistance(self.X[i], X[i])))\n",
    "            # sort the distances in ascending order\n",
    "            #distances.sort(key=lambda x: x[1])\n",
    "            # take the k nearest neighbors\n",
    "            #nearest_neighbors = distances[:n_neighbours]\n",
    "            # calculate the prediction\n",
    "            #for x in nearest_neighbors:\n",
    "                #prediction = np.round((1/n_neighbours * sum(self.t[x[0]])))   # returns prediction for each value of k\n",
    "            #predictions.append(prediction)\n",
    "\n",
    "        #return predictions\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  predictions_matrix = np.zeros((X.shape[0], len(self.n_neighbors)))\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j, n_neighbours in enumerate(self.n_neighbors):\n",
    "                distances = []\n",
    "                for k in range(len(self.X)):\n",
    "                    distances.append((k, self.__mixedDistance(self.X[k], X[i])))\n",
    "                # sort the distances in ascending order\n",
    "                distances.sort(key=lambda x: x[1])\n",
    "                # take the k nearest neighbors\n",
    "                nearest_neighbors = distances[:n_neighbours]\n",
    "                # calculate the prediction\n",
    "                prediction = np.round((1/n_neighbours * sum(self.t[j[0]])))  \n",
    "                predictions_matrix[i, j] = prediction\n",
    "        return predictions_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Computes predictions on the test set for a new set of points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions_matrix : Array of shape [n_samples, n_neighbours]\n",
    "        \"\"\"\n",
    "        # Initialize empty predictions matrix\n",
    "        predictions_matrix = np.zeros((len(X), len(self.n_neighbors)))\n",
    "        for i, x_i in enumerate(X):\n",
    "            distances = []\n",
    "            for j in range(len(self.X)):\n",
    "                distances.append((j, self.__mixedDistance(self.X[j], x_i)))\n",
    "            distances.sort(key=lambda x: x[1])\n",
    "            for k, n_neighbours in enumerate(self.n_neighbors):\n",
    "                nearest_neighbors = distances[:n_neighbours]\n",
    "                nearest_neighbors_labels = [self.t[neighbor[0]] for neighbor in nearest_neighbors]\n",
    "                #nearest_neighbors_labels = [self.t[j] for j, d in nearest_neighbors]\n",
    "                prediction = sum(nearest_neighbors_labels) / n_neighbours\n",
    "                predictions_matrix[i, k] = prediction\n",
    "\n",
    "                #round elements prediction\n",
    "                #for i in range(len(prediction)):\n",
    "                #    prediction = []\n",
    "                #   for j in range(len(prediction)):\n",
    "                #        prediction = round(prediction[i,j])\n",
    "                #        predictions_matrix[i, k] = prediction\n",
    "        #print(\"prediction\", predictions_matrix)\n",
    "        return predictions_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def predict(self, X):\n",
    "        \"\"\"\n",
    "        Computes predictions on the test set for a new set of points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions_matrix : Array of shape [n_samples, n_neighbours]\n",
    "        \"\"\"\n",
    "        # Initialize empty predictions matrix\n",
    "        predictions = []\n",
    "        for i, x_i in enumerate(X):\n",
    "            distances = []\n",
    "            for j in range(len(self.X)):\n",
    "                if self.distance_metric == 'mixedDistance':\n",
    "                    distance = self.__mixedDistance(i, j, self.weights[0], self.weights[1])\n",
    "                else:\n",
    "                    distance = self.__numericalDistance(i, j)\n",
    "                distances.append((distance, j))\n",
    "\n",
    "\n",
    "                #distances.append((j, self.__mixedDistance(self.X[j], x_i)))\n",
    "            #distances = distances.sort(key=lambda x: x[0])\n",
    "            distances = sorted(distances, key=lambda x: x[0])\n",
    "            label_indices = [x[1] for x in distances[:self.n_neighbors]]\n",
    "            labels = [self.t[i] for i in label_indices]\n",
    "            predictions.append(np.mean(labels))\n",
    "        #for k in distances[:self.n_neighbors]:\n",
    "        #    target_indices = k[1]\n",
    "        #    for i in target_indices:\n",
    "        #        targets = self.t[i]\n",
    "        #        predictions.append(np.mean(targets))\n",
    "        \n",
    "        #return predictions\n",
    "        #for k, n_neighbours in enumerate(self.n_neighbors):\n",
    "        #    nearest_neighbors = distances[:n_neighbours]\n",
    "        #    prediction = 1/n_neighbours * sum(self.t[nearest_neighbors[k][0]])\n",
    "        \n",
    "        #    predictions_matrix[i, k] = prediction\n",
    "        #print(\"Prediction\", predictions_matrix)\n",
    "        return predictions_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalParameters(training_features, training_labels, validation_features, validation_labels):\n",
    "    criterions = [\"gini\", \"entropy\"]\n",
    "    max_features = [\"sqrt\", \"log2\"]\n",
    "    max_depths = [2, 5, 7, 10, 15]\n",
    "    both_metrics = (\"\", \"\", 0, 0, 0)\n",
    "\n",
    "    for criterion in criterions:\n",
    "        for max_feature in max_features:\n",
    "            for max_depth in max_depths:\n",
    "                predictor = randomForestsClassifier(training_features, training_labels, criterion, max_feature, max_depth)\n",
    "                precision, correct, probability_mean = accuracy(predictor, validation_features, validation_labels)\n",
    "\n",
    "                best_criterion, best_max_feature, best_max_depth, best_correct, best_mean = both_metrics\n",
    "                \n",
    "                if (probability_mean < best_mean):\n",
    "                    continue\n",
    "                if (probability_mean == best_mean and correct < best_correct):\n",
    "                    continue\n",
    "                both_metrics = (criterion, max_feature, max_depth, correct, probability_mean)\n",
    "\n",
    "                print(f\"criterion = {criterion}; max_depth = {max_depth}; max_features = {max_feature}; accuracy on validation data = {precision}; number of correctly classified validation samples = {correct};\" )\n",
    "    \n",
    "    \n",
    "\n",
    "    return both_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
