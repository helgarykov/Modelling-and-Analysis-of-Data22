{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall work with the dataset found in the file 'murderdata.txt', which is a 20 x 5 data matrix where the columns correspond to\n",
    "\n",
    "Index (not for use in analysis)\n",
    "\n",
    "Number of inhabitants\n",
    "\n",
    "Percent with incomes below $5000\n",
    "\n",
    "Percent unemployed\n",
    "\n",
    "Murders per annum per 1,000,000 inhabitants\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "Helmut Spaeth,\n",
    "Mathematical Algorithms for Linear Regression,\n",
    "Academic Press, 1991,\n",
    "ISBN 0-12-656460-4.\n",
    "\n",
    "D G Kleinbaum and L L Kupper,\n",
    "Applied Regression Analysis and Other Multivariable Methods,\n",
    "Duxbury Press, 1978, page 150.\n",
    "\n",
    "http://people.sc.fsu.edu/~jburkardt/datasets/regression\n",
    "\n",
    "**What to do?**\n",
    "\n",
    "We start by loading the data; today we will study how the number of murders relates to the percentage of unemployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.loadtxt('murderdata.txt')\n",
    "N, d = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider all both features simulaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data[:,4]\n",
    "X = data[:,2:4]\n",
    "print(\"Number of training instances: %i\" % X.shape[0])\n",
    "print(\"Number of features: %i\" % X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This template makes use of Python classes. If \n",
    "# you are not yet familiar with this concept, you can \n",
    "# find a short introduction here: \n",
    "# http://introtopython.org/classes.html\n",
    "\n",
    "class LinearRegression():\n",
    "    \"\"\"\n",
    "    Linear regression implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "            \n",
    "    def fit(self, X, t):\n",
    "        \"\"\"\n",
    "        Fits the linear regression model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        t : Array of shape [n_samples, 1]\n",
    "        \"\"\"        \n",
    "\n",
    "        # make sure that we have Numpy arrays; also\n",
    "        # reshape the target array to ensure that we have\n",
    "        # a N-dimensional Numpy array (ndarray), see\n",
    "        # https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.ndarray.html\n",
    "        X = numpy.array(X).reshape((len(X), -1))\n",
    "        t = numpy.array(t).reshape((len(t), 1))\n",
    "\n",
    "        # prepend a column of ones\n",
    "        ones = numpy.ones((X.shape[0], 1))\n",
    "        X = numpy.concatenate((ones, X), axis=1)\n",
    "\n",
    "        # compute weights  (matrix inverse)\n",
    "        self.w = numpy.linalg.pinv((numpy.dot(X.T, X)))\n",
    "        self.w = numpy.dot(self.w, X.T)\n",
    "        self.w = numpy.dot(self.w, t)\n",
    "        \n",
    "        # (2) TODO: Make use of numpy.linalg.solve instead!\n",
    "        # Reason: Inverting the matrix is not very stable\n",
    "        # from a numerical perspective; directly solving\n",
    "        # the linear system of equations is usually better.\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Computes predictions for a new set of points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : Array of shape [n_samples, 1]\n",
    "        \"\"\"                     \n",
    "        \n",
    "        # (1) TODO: Compute the predictions for the\n",
    "        # array of input points\n",
    "        \n",
    "        # predictions = ...\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us instantiate a LinearRegression object and call the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the computed model coefficients ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model coefficients:\")\n",
    "print(model.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) evaluation of results\n",
    "preds = model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(t, preds)\n",
    "plt.xlabel(\"Murders per annum per 1,000,000 inhabitants\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.xlim([0,50])\n",
    "plt.ylim([0,50])\n",
    "plt.title(\"Evaluation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
