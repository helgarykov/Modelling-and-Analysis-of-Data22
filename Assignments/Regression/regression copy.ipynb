{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data file reading\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [1984. 1988. 1908. 1904. 1992. 1920. 1980. 1956. 1924. 2000. 1900. 1968.\n",
      " 1896. 1964. 2008. 2004. 1932. 1928. 1952. 1948. 1912.]\n",
      "y [ 9.99  9.92 10.8  11.    9.96 10.8  10.25 10.5  10.6   9.87 11.    9.95\n",
      " 12.   10.    9.69  9.85 10.3  10.8  10.4  10.3  10.8 ]\n"
     ]
    }
   ],
   "source": [
    "# teams = pd.read_cvs(\"men-olympics.txt\")\n",
    "# Load the data\n",
    "#years = np.loadtxt(\"men-olympics-100.txt\")\n",
    "\n",
    "# Read the data into a numpy array\n",
    "raw = np.genfromtxt(\"men-olympics-100.txt\", delimiter=\"\")\n",
    "\n",
    "train, test = train_test_split(raw, test_size=.2, random_state=1)\n",
    "# Set the predictions\n",
    "\n",
    "#predictor = raw[:,0] # here olympic years (get all elements in 1.row arr[0,:]; all elements in the 1. col: arr[:,0]\n",
    "#target = raw[:,1]    #\"winning_times\"\n",
    "\n",
    "# Split the data into the train (80%) and test (20%) sets\n",
    "\n",
    "\n",
    "# Matrix X as a train data (predictor) and matrix y as a target matrix (target)\n",
    "X = train[:,0]      # elements of the 0. column (years)\n",
    "y= train[:,1]       # elements of the 1. column (winning times)\n",
    "print(\"X\", X)\n",
    "print(\"y\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_mean 1950 and X_std 36\n"
     ]
    }
   ],
   "source": [
    "# Calculate x_mean and standard deviaiton for the predictor columns (here one column - years)\n",
    "X_mean = X.mean()\n",
    "X_std = X.std()         #It is important to note that the standard deviation calculated by numpy is the population standard deviation, if you would like to calculate the sample standard deviation, you can set the ddof argument to 1 for np.std() or use X.std(ddof=1)\n",
    "print(\"X_mean %d and X_std %d\" % (X_mean, X_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91228354  1.02238673 -1.17967699 -1.28978018  1.13248991 -0.84936743\n",
      "  0.80218035  0.14156124 -0.73926425  1.35269628 -1.39988336  0.4718708\n",
      " -1.50998655  0.36176761  1.57290265  1.46279947 -0.51905788 -0.62916106\n",
      "  0.03145805 -0.07864513 -1.06957381]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data in the 0.col (years)\n",
    "X = (X -X_mean) / X_std\n",
    "print(X)\n",
    "# for element in X.tolist():\n",
    "#    print(element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.91228354]\n",
      " [ 1.          1.02238673]\n",
      " [ 1.         -1.17967699]\n",
      " [ 1.         -1.28978018]\n",
      " [ 1.          1.13248991]\n",
      " [ 1.         -0.84936743]\n",
      " [ 1.          0.80218035]\n",
      " [ 1.          0.14156124]\n",
      " [ 1.         -0.73926425]\n",
      " [ 1.          1.35269628]\n",
      " [ 1.         -1.39988336]\n",
      " [ 1.          0.4718708 ]\n",
      " [ 1.         -1.50998655]\n",
      " [ 1.          0.36176761]\n",
      " [ 1.          1.57290265]\n",
      " [ 1.          1.46279947]\n",
      " [ 1.         -0.51905788]\n",
      " [ 1.         -0.62916106]\n",
      " [ 1.          0.03145805]\n",
      " [ 1.         -0.07864513]\n",
      " [ 1.         -1.06957381]]\n"
     ]
    }
   ],
   "source": [
    "# Add the intercept to X (append ones)\n",
    "X = np.array(X).reshape((len(X), -1))\n",
    "ones = np.ones((X.shape[0], 1))                                         # X = X.reshape(-1, 1) - reshape a 1D array X to a 2D-array (the array X to have 1 column and as many rows as needed to fit all the elements.)\n",
    "X = np.append(ones, X, axis=1)    #we want to append the values along the first axis (rows), so we set axis=1. This should reshape your 1D array to have 2 dimensions and concatenate the ones array to the left of the X array\n",
    "print(X)    #print(X.shape[0] - number of rows, print(X.shape[1] - nr of columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the polynomial transformation\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "X = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9122835396978074, 1.022386725523405, -1.179676990988546, -1.2897801768141437, 1.1324899113490026, -0.8493674335117534, 0.8021803538722099, 0.14156123891862452, -0.7392642476861558, 1.3526962830001976, -1.3998833626397411, 0.4718707963954172, -1.5099865484653388, 0.3617676105698196, 1.5729026546513927, 1.462799468825795, -0.5190578760349608, -0.6291610618605583, 0.031458053093026975, -0.07864513273257057, -1.0695738051629484]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9122835396978074, 1.022386725523405, -1.179676990988546, -1.2897801768141437, 1.1324899113490026, -0.8493674335117534, 0.8021803538722099, 0.14156123891862452, -0.7392642476861558, 1.3526962830001976, -1.3998833626397411, 0.4718707963954172, -1.5099865484653388, 0.3617676105698196, 1.5729026546513927, 1.462799468825795, -0.5190578760349608, -0.6291610618605583, 0.031458053093026975, -0.07864513273257057, -1.0695738051629484]\n",
      "[0.8322612568035609, 1.0452746165264701, 1.3916378030677903, 1.6635329045027238, 1.2825333993072716, 0.7214250371103428, 0.6434933201385439, 0.020039584364175893, 0.5465116279069779, 1.8297872340425507, 1.9596734289955489, 0.22266204849084525, 2.2800593765462667, 0.13087580405739666, 2.4740227610093983, 2.139782285997028, 0.26942107867392473, 0.39584364176150527, 0.000989609104403704, 0.006185056902523642, 1.1439881246907488]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9122835396978074, 1.022386725523405, -1.179676990988546, -1.2897801768141437, 1.1324899113490026, -0.8493674335117534, 0.8021803538722099, 0.14156123891862452, -0.7392642476861558, 1.3526962830001976, -1.3998833626397411, 0.4718707963954172, -1.5099865484653388, 0.3617676105698196, 1.5729026546513927, 1.462799468825795, -0.5190578760349608, -0.6291610618605583, 0.031458053093026975, -0.07864513273257057, -1.0695738051629484]\n",
      "[0.8322612568035609, 1.0452746165264701, 1.3916378030677903, 1.6635329045027238, 1.2825333993072716, 0.7214250371103428, 0.6434933201385439, 0.020039584364175893, 0.5465116279069779, 1.8297872340425507, 1.9596734289955489, 0.22266204849084525, 2.2800593765462667, 0.13087580405739666, 2.4740227610093983, 2.139782285997028, 0.26942107867392473, 0.39584364176150527, 0.000989609104403704, 0.006185056902523642, 1.1439881246907488]\n",
      "[0.7592582453100984, 1.0686748924632306, -1.6416830960689217, -2.1455917637056694, 1.452456135683627, -0.6127549322415333, 0.5161976992631404, 0.002836828390007036, -0.4040165074563884, 2.475146390170571, -2.743314229458041, 0.10506771814841015, -3.442858988287129, 0.04734662691524829, 3.8913969684596506, 3.130072391359298, -0.13984513285553543, -0.24904940598141911, 3.1131175747674596e-05, -0.00048642462105747363, -1.2235797315867099]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9122835396978074, 1.022386725523405, -1.179676990988546, -1.2897801768141437, 1.1324899113490026, -0.8493674335117534, 0.8021803538722099, 0.14156123891862452, -0.7392642476861558, 1.3526962830001976, -1.3998833626397411, 0.4718707963954172, -1.5099865484653388, 0.3617676105698196, 1.5729026546513927, 1.462799468825795, -0.5190578760349608, -0.6291610618605583, 0.031458053093026975, -0.07864513273257057, -1.0695738051629484]\n",
      "[0.8322612568035609, 1.0452746165264701, 1.3916378030677903, 1.6635329045027238, 1.2825333993072716, 0.7214250371103428, 0.6434933201385439, 0.020039584364175893, 0.5465116279069779, 1.8297872340425507, 1.9596734289955489, 0.22266204849084525, 2.2800593765462667, 0.13087580405739666, 2.4740227610093983, 2.139782285997028, 0.26942107867392473, 0.39584364176150527, 0.000989609104403704, 0.006185056902523642, 1.1439881246907488]\n",
      "[0.7592582453100984, 1.0686748924632306, -1.6416830960689217, -2.1455917637056694, 1.452456135683627, -0.6127549322415333, 0.5161976992631404, 0.002836828390007036, -0.4040165074563884, 2.475146390170571, -2.743314229458041, 0.10506771814841015, -3.442858988287129, 0.04734662691524829, 3.8913969684596506, 3.130072391359298, -0.13984513285553543, -0.24904940598141911, 3.1131175747674596e-05, -0.00048642462105747363, -1.2235797315867099]\n",
      "[0.6926587995762428, 1.092599023954559, 1.9366557749273456, 2.7673417243632685, 1.6448919203386656, 0.5204540841696595, 0.41408365306292655, 0.0004015849414889229, 0.29867495943753514, 3.3481213218650883, 3.8403199483111727, 0.049578387838139525, 5.19867076057655, 0.017128476087670083, 6.120788621992566, 4.578668231466668, 0.07258771763382113, 0.15669218872301094, 9.793261795187013e-07, 3.8254928887455354e-05, 1.3087088294334563]\n"
     ]
    }
   ],
   "source": [
    "# Print X transpose\n",
    "\n",
    "for element in X.T.tolist():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-08 1.20450354e-08 1.45082878e-08 1.74752840e-08\n",
      " 2.10490414e-08 2.53536449e-08 3.05385551e-08 3.67837977e-08\n",
      " 4.43062146e-08 5.33669923e-08 6.42807312e-08 7.74263683e-08\n",
      " 9.32603347e-08 1.12332403e-07 1.35304777e-07 1.62975083e-07\n",
      " 1.96304065e-07 2.36448941e-07 2.84803587e-07 3.43046929e-07\n",
      " 4.13201240e-07 4.97702356e-07 5.99484250e-07 7.22080902e-07\n",
      " 8.69749003e-07 1.04761575e-06 1.26185688e-06 1.51991108e-06\n",
      " 1.83073828e-06 2.20513074e-06 2.65608778e-06 3.19926714e-06\n",
      " 3.85352859e-06 4.64158883e-06 5.59081018e-06 6.73415066e-06\n",
      " 8.11130831e-06 9.77009957e-06 1.17681195e-05 1.41747416e-05\n",
      " 1.70735265e-05 2.05651231e-05 2.47707636e-05 2.98364724e-05\n",
      " 3.59381366e-05 4.32876128e-05 5.21400829e-05 6.28029144e-05\n",
      " 7.56463328e-05 9.11162756e-05 1.09749877e-04 1.32194115e-04\n",
      " 1.59228279e-04 1.91791026e-04 2.31012970e-04 2.78255940e-04\n",
      " 3.35160265e-04 4.03701726e-04 4.86260158e-04 5.85702082e-04\n",
      " 7.05480231e-04 8.49753436e-04 1.02353102e-03 1.23284674e-03\n",
      " 1.48496826e-03 1.78864953e-03 2.15443469e-03 2.59502421e-03\n",
      " 3.12571585e-03 3.76493581e-03 4.53487851e-03 5.46227722e-03\n",
      " 6.57933225e-03 7.92482898e-03 9.54548457e-03 1.14975700e-02\n",
      " 1.38488637e-02 1.66810054e-02 2.00923300e-02 2.42012826e-02\n",
      " 2.91505306e-02 3.51119173e-02 4.22924287e-02 5.09413801e-02\n",
      " 6.13590727e-02 7.39072203e-02 8.90215085e-02 1.07226722e-01\n",
      " 1.29154967e-01 1.55567614e-01 1.87381742e-01 2.25701972e-01\n",
      " 2.71858824e-01 3.27454916e-01 3.94420606e-01 4.75081016e-01\n",
      " 5.72236766e-01 6.89261210e-01 8.30217568e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Generate an array of \"alpha\" values which is our lamda vals\n",
    "alpha_vals = np.logspace(-8, 0, 100, base=10)   # start -8, end 0, 100 vals\n",
    "print(alpha_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Create an Identity matrix for X and set the top left element to 0\n",
    "\n",
    "I = np.identity(X.shape[1])\n",
    "I[0][0] = 0\n",
    "print(I)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 1.e-08 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 1.e-08 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 1.e-08 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 1.e-08 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-08 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-08 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-08 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-08 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 1.e-08\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  1.e-08 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 1.e-08 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 1.e-08 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 1.e-08 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      "  0.e+00 0.e+00 0.e+00 0.e+00 1.e-08]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the penalty matrix \n",
    "penalty = alpha_vals[0] * I # alpha = 1\n",
    "print(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.11438792e+02  3.31569762e+03 -1.40395844e+02 -3.81678755e+03\n",
      "  1.51691249e+02 -2.68429760e+00  1.71556152e-06 -1.14707371e+01\n",
      "  2.60193044e+00 -8.06800549e-02  0.00000000e+00 -5.84436742e-02\n",
      " -4.11829069e-02 -8.06800545e-02  1.22854298e-01]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the coefficients w_hat\n",
    "w_hat = np.linalg.inv(X.T @ X + penalty) @ X.T @ y\n",
    "print(w_hat)    # [\"intercept-w\", \"years-w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          0.58197398  1.          0.58197398  0.33869372\n",
      "   1.          0.58197398  0.33869372  0.19711093  1.          0.58197398\n",
      "   0.33869372  0.19711093  0.11471343]\n",
      " [ 1.          1.          0.25166442  1.          0.25166442  0.06333498\n",
      "   1.          0.25166442  0.06333498  0.01593916  1.          0.25166442\n",
      "   0.06333498  0.01593916  0.00401132]\n",
      " [ 1.          1.          0.69207717  1.          0.69207717  0.47897081\n",
      "   1.          0.69207717  0.47897081  0.33148476  1.          0.69207717\n",
      "   0.47897081  0.33148476  0.22941303]\n",
      " [ 1.          1.         -1.23472858  1.         -1.23472858  1.52455468\n",
      "   1.         -1.23472858  1.52455468 -1.88241124  1.         -1.23472858\n",
      "   1.52455468 -1.88241124  2.32426696]\n",
      " [ 1.          1.          1.2425931   1.          1.2425931   1.54403761\n",
      "   1.          1.2425931   1.54403761  1.91861047  1.          1.2425931\n",
      "   1.54403761  1.91861047  2.38405213]\n",
      " [ 1.          1.         -0.40895469  1.         -0.40895469  0.16724394\n",
      "   1.         -0.40895469  0.16724394 -0.06839519  1.         -0.40895469\n",
      "   0.16724394 -0.06839519  0.02797054]]\n"
     ]
    }
   ],
   "source": [
    "# To make predictions, we need to do the same with the test set (\"winning_times\")\n",
    "test_X = test[:,0] \n",
    "\n",
    "# Scale the set by using the mean & std of the training set\n",
    "test_X = (test_X - X_mean) / X_std\n",
    "\n",
    "test_X = np.array(test_X).reshape((len(test_X), -1))\n",
    "ones = np.ones((test_X.shape[0], 1))                                         # X = X.reshape(-1, 1) - reshape a 1D array X to a 2D-array (the array X to have 1 column and as many rows as needed to fit all the elements.)\n",
    "test_X = np.append(ones, test_X, axis=1)    #we want to append the values along the first axis (rows), so we set axis=1. This should reshape your 1D array to have 2 dimensions and concatenate the ones array to the left of the X array\n",
    "\n",
    "# Define the polynomial transformation\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "test_X = poly.fit_transform(test_X)\n",
    "\n",
    "print(test_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.15325517 10.28012786 10.10259321 11.03844842  9.85091463 10.43827846]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions for the winning times\n",
    "predictions = test_X @ w_hat\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal alpha by defining the ridge regression model\n",
    "\n",
    "def ridge_fit(train, predictor, target, alpha):\n",
    "    X = train[:,0]  # predictor  \n",
    "    y = train[:,1]  # target\n",
    "\n",
    "    X_mean = X.mean()\n",
    "    X_std = X.std()\n",
    "\n",
    "    X = (X -X_mean) / X_std\n",
    "    X = np.array(X).reshape((len(X), -1))\n",
    "    ones = np.ones((X.shape[0], 1))                                         # X = X.reshape(-1, 1) - reshape a 1D array X to a 2D-array (the array X to have 1 column and as many rows as needed to fit all the elements.)\n",
    "    X = np.append(ones, X, axis=1) \n",
    "\n",
    "    penalty = alpha * np.identity(X.shape[1])\n",
    "    penalty[0][0] = 0 \n",
    "\n",
    "    w_hat = np.linalg.inv(X.T @ X + penalty) @ X.T @ y\n",
    "\n",
    "    return w_hat, X_mean, X_std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same on the test set\n",
    "def ridge_predict(test, predictor, x_mean, x_std, w_hat):\n",
    "    test_X = test[:,0]\n",
    "    test_X = (test_X - X_mean) / X_std\n",
    "    \n",
    "    test_X = np.array(test_X).reshape((len(test_X), -1))\n",
    "    ones = np.ones((test_X.shape[0], 1))                                         # X = X.reshape(-1, 1) - reshape a 1D array X to a 2D-array (the array X to have 1 column and as many rows as needed to fit all the elements.)\n",
    "    test_X = np.append(ones, test_X, axis=1) \n",
    "\n",
    "    predictions = test_X @ w_hat\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha 0.11445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "errors = []\n",
    "alphas = np.logspace(0, 1, 100, base=10) \n",
    "\n",
    "for alpha in alphas:\n",
    "    w_hat, X_mean, X_std = ridge_fit(train, X, y, alpha)\n",
    "    predictions = ridge_predict(test, X, X_mean, X_std, w_hat)\n",
    "    errors.append(mean_absolute_error(test[:,1], predictions))  # a corresponding error for each aplha value\n",
    "#print(errors)\n",
    "\n",
    "# We pick the alpha where error is the lowest\n",
    "# The higher the error, the more underfitted the regression model is\n",
    "optimal_alpha = np.min(errors)\n",
    "print(\"Optimal alpha {:.5f}\".format(optimal_alpha))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([10.41809524, -0.47969037]), 1950.857142857143, 36.32955731486248)\n",
      "[10.41809524 -0.47709023]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficients_alpha_0 = ridge_fit(train, X, y, 0)\n",
    "print(coefficients_alpha_0)\n",
    "\n",
    "result = ridge_fit(train, X, y, optimal_alpha)\n",
    "coefficients_optimal_alpha = result[0]\n",
    "print(coefficients_optimal_alpha)\n",
    "\n",
    "#optimal_alpha = np.array([optimal_alpha]).reshape(-1, 1) # convert optimal_alpha to an array of shape (1,)\n",
    "plt.plot(optimal_alpha, coefficients_optimal_alpha)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the validation errors as a function of lambda\n",
    "plt.plot(alphas, errors)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Validation Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare our model with the sklearn implementation\n",
    "#from sklearn.linear_model import Ridge\n",
    "\n",
    "#ridge = Ridge(alpha=alpha_vals)\n",
    "#X = np.array(X).reshape((len(X), -1))\n",
    "#ridge.fit(X[:,0], y)\n",
    "#Ridge(alpha=alpha_vals)\n",
    "#ridge.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean athlets 123\n",
      "Standard deviation athlets 53\n",
      "Mean events 64\n",
      "Standard deviation events 24\n",
      "Standardized data, matrix X not prepended with ones:\n",
      " [[ 0.51466717  0.79063786]\n",
      " [-1.00615113 -0.74902534]\n",
      " [ 1.38635571  1.16515053]\n",
      " [-0.89487175 -1.20676305]]\n",
      "X^T * X:\n",
      " [[4.00000000e+00 0.00000000e+00 2.22044605e-16]\n",
      " [0.00000000e+00 4.00000000e+00 3.85575929e+00]\n",
      " [2.22044605e-16 3.85575929e+00 4.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "athlets = np. array([[151, 83], [69, 46], [198, 92], [75,35]])\n",
    "mean_althlets = np.mean(athlets, axis=0)\n",
    "standard_deviation_althlets = np.std(athlets, axis=0).tolist()\n",
    "standard_deviation = np.std(athlets, axis=0)\n",
    "print(\"Mean athlets %d\" % mean_althlets[0].item())\n",
    "print(\"Standard deviation athlets %d\" % standard_deviation_althlets[0])\n",
    "print(\"Mean events %d\" % mean_althlets[1].item())\n",
    "print(\"Standard deviation events %d\" % standard_deviation_althlets[1])\n",
    "\n",
    "# We standardize the values of the observations in the two columns()/for the two variables\n",
    "standardized_data = []\n",
    "for row in athlets:\n",
    "    new_athlets = (row[0] - mean_althlets[0]) / standard_deviation_althlets[0]\n",
    "    new_events = (row[1] - mean_althlets[1]) / standard_deviation_althlets[1]\n",
    "    standardized_data.append([new_athlets, new_events])\n",
    "standardized_data = np.array(standardized_data)\n",
    "print(\"Standardized data, matrix X not prepended with ones:\\n\", standardized_data)\n",
    "\n",
    "# Compute X^T * X, where X needs to be appended with a column of ones\n",
    "ones = np.ones((standardized_data.shape[0], 1))\n",
    "data_to_standardize = np.hstack((ones,standardized_data))\n",
    "matrix_data = data_to_standardize.T @ data_to_standardize       # element for element multiplication: X^T * X\n",
    "print(\"X^T * X:\\n\", matrix_data)\n",
    "\n",
    "#standardized_athlets = np.array([])\n",
    "#for row in athlets:\n",
    "#    new_athlets = np.array((row[0] - mean_althlets[0]) / standard_deviation_althlets[0])\n",
    "#    new_events = np.array((row[1] - mean_althlets[1]) / standard_deviation_althlets[1])\n",
    "#    standardized_athlets.append([new_athlets, new_events])\n",
    "# standardized_athlets = np.concatenate([new_athlets, new_events], axis=0)\n",
    "\n",
    "\n",
    "#for i, item in enumerate(athlets):\n",
    "#    for j, sub_item in enumerate(item):\n",
    "#        new_val = (sub_item - mean_althlets[j]) / standard_deviation_althlets[j]\n",
    "#        athlets[i][j] = new_val\n",
    "#        print(\"Standardarzed value: {:.1f}\".format(new_val))\n",
    "\n",
    "# standardized_athlets = [[(sub_item - mean_althlets[j]) / standard_deviation_althlets[j] for j, sub_item in enumerate(item)] for i, item in enumerate(data_to_standardize)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# matrix_data = np.cov(standardized_athlets, rowvar=False) //computes the covariance matrix\n",
    "\n",
    "\n",
    "# Print the elements of the 2D array (matrix X)\n",
    "#for i in range(matrix_data.shape[0]):\n",
    "#    for j in range(matrix_data.shape[1]):\n",
    "#            print(matrix_data[i][j], end=' ')\n",
    "#    print()\n",
    "\n",
    "\n",
    "#matrix_data = np.matmul(data_to_standardize.T, data_to_standardize)\n",
    "# for i in range(matrix_data.shape[0]):\n",
    "#     for j in range(matrix_data.shape[1]):\n",
    "#         print(matrix_data[i][j], end=' ')\n",
    "#     print()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
